# coding: utf-8

"""
    QuantCDN API

    Unified API for QuantCDN Admin and QuantCloud Platform services

    The version of the OpenAPI document: 4.6.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import json
import pprint
from pydantic import BaseModel, ConfigDict, Field, StrictStr, ValidationError, field_validator
from typing import Any, List, Optional
from quantcdn.models.chat_inference200_response_response_tool_use_one_of import ChatInference200ResponseResponseToolUseOneOf
from quantcdn.models.chat_inference200_response_response_tool_use_one_of1_inner import ChatInference200ResponseResponseToolUseOneOf1Inner
from pydantic import StrictStr, Field
from typing import Union, List, Set, Optional, Dict
from typing_extensions import Literal, Self

CHATINFERENCE200RESPONSERESPONSETOOLUSE_ONE_OF_SCHEMAS = ["ChatInference200ResponseResponseToolUseOneOf", "List[ChatInference200ResponseResponseToolUseOneOf1Inner]"]

class ChatInference200ResponseResponseToolUse(BaseModel):
    """
    Tool use request(s). Can be a single object or array of objects. Only present when AI requests tools.
    """
    # data type: ChatInference200ResponseResponseToolUseOneOf
    oneof_schema_1_validator: Optional[ChatInference200ResponseResponseToolUseOneOf] = None
    # data type: List[ChatInference200ResponseResponseToolUseOneOf1Inner]
    oneof_schema_2_validator: Optional[List[ChatInference200ResponseResponseToolUseOneOf1Inner]] = Field(default=None, description="Multiple tool requests")
    actual_instance: Optional[Union[ChatInference200ResponseResponseToolUseOneOf, List[ChatInference200ResponseResponseToolUseOneOf1Inner]]] = None
    one_of_schemas: Set[str] = { "ChatInference200ResponseResponseToolUseOneOf", "List[ChatInference200ResponseResponseToolUseOneOf1Inner]" }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )


    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator('actual_instance')
    def actual_instance_must_validate_oneof(cls, v):
        instance = ChatInference200ResponseResponseToolUse.model_construct()
        error_messages = []
        match = 0
        # validate data type: ChatInference200ResponseResponseToolUseOneOf
        if not isinstance(v, ChatInference200ResponseResponseToolUseOneOf):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ChatInference200ResponseResponseToolUseOneOf`")
        else:
            match += 1
        # validate data type: List[ChatInference200ResponseResponseToolUseOneOf1Inner]
        try:
            instance.oneof_schema_2_validator = v
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when setting `actual_instance` in ChatInference200ResponseResponseToolUse with oneOf schemas: ChatInference200ResponseResponseToolUseOneOf, List[ChatInference200ResponseResponseToolUseOneOf1Inner]. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when setting `actual_instance` in ChatInference200ResponseResponseToolUse with oneOf schemas: ChatInference200ResponseResponseToolUseOneOf, List[ChatInference200ResponseResponseToolUseOneOf1Inner]. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # deserialize data into ChatInference200ResponseResponseToolUseOneOf
        try:
            instance.actual_instance = ChatInference200ResponseResponseToolUseOneOf.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into List[ChatInference200ResponseResponseToolUseOneOf1Inner]
        try:
            # validation
            instance.oneof_schema_2_validator = json.loads(json_str)
            # assign value to actual_instance
            instance.actual_instance = instance.oneof_schema_2_validator
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when deserializing the JSON string into ChatInference200ResponseResponseToolUse with oneOf schemas: ChatInference200ResponseResponseToolUseOneOf, List[ChatInference200ResponseResponseToolUseOneOf1Inner]. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when deserializing the JSON string into ChatInference200ResponseResponseToolUse with oneOf schemas: ChatInference200ResponseResponseToolUseOneOf, List[ChatInference200ResponseResponseToolUseOneOf1Inner]. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(self) -> Optional[Union[Dict[str, Any], ChatInference200ResponseResponseToolUseOneOf, List[ChatInference200ResponseResponseToolUseOneOf1Inner]]]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())


